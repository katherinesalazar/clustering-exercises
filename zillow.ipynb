{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zillow\n",
    "\n",
    "- Acquire & Summarize\n",
    "    - 1. Acquire data from mySQL using the python module to connect and query. You will want to end with a single dataframe. Make sure to include: the logerror, all fields related to the properties that are available. You will end up using all the tables in the database.\n",
    "\n",
    "            - Be sure to do the correct join (inner, outer, etc.). We do not want to eliminate properties purely because they may have a null value for airconditioningtypeid.\n",
    "            - Only include properties with a transaction in 2017, and include only the last transaction for each property (so no duplicate property ID's), along with zestimate error and date of transaction.\n",
    "            - Only include properties that include a latitude and longitude value.\n",
    "    - 2. Summarize your data (summary stats, info, dtypes, shape, distributions, value_counts, etc.)\n",
    "\n",
    "    - 3. Write a function that takes in a dataframe of observations and attributes and returns a dataframe where each row is an atttribute name, the first column is the number of rows with missing values for that attribute, and the second column is percent of total rows that have missing values for that attribute. Run the function and document takeaways from this on how you want to handle missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from env import username, host, password\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connection(database, username=username, host=host, password=password):\n",
    "    '''get URL with username, host, and password from env '''\n",
    "    \n",
    "    return f\"mysql+pymysql://{username}:{password}@{host}/{database}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql_data(database,query):\n",
    "    ''' \n",
    "        Take in a database and query\n",
    "        check if csv exists for the queried database\n",
    "        if it does read from the csv\n",
    "        if it does not create the csv then read from the csv  \n",
    "    '''\n",
    "    \n",
    "    if os.path.isfile(f'{database}_query.csv') == False:   # check for the file\n",
    "        \n",
    "        df = pd.read_sql(query, get_connection(database))  # create df for query\n",
    "        \n",
    "        df.to_csv(f'{database}_query.csv',index = False)   # cache file\n",
    "        \n",
    "    return pd.read_csv(f'{database}_query.csv') # return contents of file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
